{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv \n",
    "from textblob import TextBlob\n",
    "from ast import literal_eval\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Dataset Australian_User_reviews.json\n",
    "    Contiene datos de las recomendaciones y comentarios de los jugadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cargamos los datos desde la carpeta Datasets\n",
    "##Obserbamos que el Dataset tiene columnas con datos anidados en forma de diccionarios por lo que\n",
    "##deberemos tratarlo linea por linea\n",
    "\n",
    "# Creamos esta funcion para corregir y cargar cada linea del archivo 'australian_user_reviews.json' original\n",
    "def cargar_y_corregir_linea(linea):\n",
    "    # reemplaza las comillas simples con dobles y corrige valores booleanos\n",
    "    linea_corregida = linea.replace(\"'\", '\"').replace('True', 'true').replace('False', 'false')\n",
    "    return json.loads(linea_corregida)\n",
    "\n",
    "# lista para almacenar los datos desanidados\n",
    "data_list = []\n",
    "\n",
    "# extraemos números de la columna 'funny'\n",
    "numero_regex = re.compile(r'\\d+')\n",
    "\n",
    "# lee el archivo 'australian_user_reviews.json' original, corrige y procesa cada línea\n",
    "with open('./Datasets/australian_user_reviews.json', 'r', encoding='utf-8') as archivo_json:\n",
    "    for linea in archivo_json:\n",
    "        try:\n",
    "            entrada = cargar_y_corregir_linea(linea)\n",
    "            user_id = entrada['user_id']\n",
    "            user_url = entrada['user_url']\n",
    "            # iteramos sobre cada reseña\n",
    "            for reseña in entrada['reviews']:\n",
    "                # estraemos el numero de la columna 'funny'\n",
    "                funny_valor = re.search(numero_regex, reseña.get('funny', ''))\n",
    "                if funny_valor:\n",
    "                    funny = int(funny_valor.group())\n",
    "                else:\n",
    "                    funny = None\n",
    "                \n",
    "                # elimina 'Posted' de la columna 'posted'\n",
    "                posted = reseña.get('posted', '').replace('Posted ', '', 1) \n",
    "\n",
    "                reseña_dict = {\n",
    "                    'user_id': user_id,\n",
    "                    'user_url': user_url,\n",
    "                    'funny': funny,\n",
    "                    'posted': posted,\n",
    "                    'item_id': int(reseña.get('item_id', '')),  # convierte a entero\n",
    "                    'helpful': reseña.get('helpful', ''),\n",
    "                    'recommend': reseña.get('recommend', ''),\n",
    "                    'review': reseña.get('review', '')  # mantiene el texto original de la review\n",
    "                }\n",
    "                data_list.append(reseña_dict)\n",
    "        except json.JSONDecodeError as e:\n",
    "            None\n",
    "\n",
    "# crea el DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciona solo la columna 'review'\n",
    "review_column = df[['review']]\n",
    "\n",
    "# Guarda la columna en un archivo parquet\n",
    "review_column.to_parquet('./Datasets/review_column.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplaza los valores NaN por None en el DataFrame\n",
    "df = df.where(df.notna(), None)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La columna ['posted'] presenta formato de fecha completo y algunas sin el año, \n",
    "# deduzco que el año corresponde al año 2016 en curzo en el momento de la extraccion de los datos\n",
    "#por lo que realizaremos la extraccion, transformacion y asignacion del año correcto \n",
    "\n",
    "# Definimos una función para extraer y convertir la fecha\n",
    "def extract_date(posted_str):\n",
    "    if not isinstance(posted_str, str):\n",
    "        return None\n",
    "    \n",
    "    # Elimina el punto y espacios en blanco al principio y al final\n",
    "    date_str = posted_str.replace('.', '').strip()\n",
    "    try:\n",
    "        # Intenta convertir la cadena de fecha en un objeto de fecha utilizando datetime.strptime\n",
    "        date_obj = datetime.strptime(date_str, '%B %d, %Y').date()\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Intenta nuevamente con el formato '%B %d' si la conversión falla\n",
    "            date_obj = datetime.strptime(date_str, '%B %d').date()\n",
    "            # Si solo tiene mes y día y no se proporcionó el año, asumimos el año 2016\n",
    "            date_obj = date_obj.replace(year=2016)\n",
    "        except ValueError:\n",
    "            # Si no se puede convertir a ninguna de las dos formas, devuelve None\n",
    "            date_obj = None\n",
    "\n",
    "    return date_obj\n",
    "\n",
    "# Aplica la función extract_date a la columna 'posted'\n",
    "df['posted'] = df['posted'].apply(extract_date)\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'posted' a datetime con manejo de errores\n",
    "df['posted'] = pd.to_datetime(df['posted'], errors='coerce')\n",
    "\n",
    "# Extraemos el año y sobrescribimos la columna 'posted' con estos valores, y luego convertimos a int\n",
    "df['posted'] = df['posted'].dt.year.astype('Int64')\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame para verificar la conversión\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 'user_url' porque no nos aporta informacion necesaria\n",
    "df.drop('user_url', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 'helpful' porque no nos aporta informacion necesaria\n",
    "df.drop('helpful', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 'funny' porque no nos aporta informacion necesaria\n",
    "df.drop('funny', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a- Analisis de Sentimientos\n",
    "    realizamos el analisis y adjuntamos la nueva columna al Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion que nos permita analizar el sentimiento de las reseñas junto con su \n",
    "# recomendación. Esta función evaluará si una reseña es positiva, neutral o negativa, \n",
    "# considerando también si la recomendación asociada es verdadera (positiva) o falsa (negativa). \n",
    "# Luego, aplicaremos esta función a cada reseña en nuestro DataFrame para obtener \n",
    "# un análisis de sentimiento más completo.\n",
    "\n",
    "def get_sentiment_with_recommend(recommend, review):\n",
    "    if isinstance(review, str):  # Verifica si el tipo de review es string\n",
    "        if recommend:  # Verifica si la recomendación es verdadera\n",
    "            analysis = TextBlob(str(review))  # Convierte a cadena y analiza el texto de la reseña\n",
    "            polarity = analysis.sentiment.polarity\n",
    "            if polarity > 0:\n",
    "                return 2  # Positivo si polaridad > 0\n",
    "            else:\n",
    "                return 1  # Neutral si polaridad <= 0 y recommend true\n",
    "        else:\n",
    "            return 0  # No recomendado, se asume neutral o negativo\n",
    "    else:\n",
    "        return 1  # No hay reseña, se asume neutral\n",
    "\n",
    "# Convertimos la columna 'review' a cadena (str)\n",
    "df['review'] = df['review'].astype(str)\n",
    "\n",
    "# Aplicamos la función a cada review\n",
    "df['sentiment_analysis'] = df.apply(lambda x: get_sentiment_with_recommend(x['recommend'], x['review']), axis=1)\n",
    "\n",
    "# Reemplazamos la columna 'review' con la nueva columna 'sentiment_analysis'\n",
    "df.drop('review', axis=1, inplace=True)\n",
    "# Renombramos a la columna 'sentiment_analysis' como 'review' \n",
    "df.rename(columns={'sentiment_analysis': 'review'}, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el df resultante en formato parquet \n",
    "df.to_parquet('./Datasets/user_reviews.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Dataset Australian_User_items.json\n",
    "    Contiene datos de Usuarios como Items y Tiempo de Juego "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cargamos los datos desde la carpeta Datasets\n",
    "##Obserbamos que el Dataset tiene columnas con datos anidados en forma de diccionarios por lo que\n",
    "##deberemos tratarlo linea por linea\n",
    "## Las Lineas con Errores de formato no se cargan en el df (55010 lineas)\n",
    "\n",
    "# Lista para almacenar los datos desanidados\n",
    "data_list = []\n",
    "\n",
    "# Función para corregir y cargar cada línea del archivo 'australian_users_items.json' original\n",
    "def cargar_y_corregir_linea(linea):\n",
    "    # reemplaza las comillas simples con dobles\n",
    "    linea_corregida = linea.replace(\"'\", '\"')\n",
    "    return json.loads(linea_corregida)\n",
    "\n",
    "# Crea y abre un archivo 'australian_users_items.csv' para escribir los datos\n",
    "with open('australian_users_items.csv', 'w', newline='', encoding='utf-8') as archivo_csv:\n",
    "    writer = csv.writer(archivo_csv)\n",
    "    \n",
    "    # Escribimos los nombres de las columnas\n",
    "    writer.writerow(['user_id', 'user_url', 'item_id', 'item_name', 'playtime_forever', 'playtime_2weeks'])\n",
    "    \n",
    "    # Inicializamos el contador de errores\n",
    "    errores_count = 0\n",
    "\n",
    "    # Lee el archivo 'australian_users_items.json' original, corrige y procesa cada línea\n",
    "    with open('./Datasets/australian_users_items.json', 'r', encoding='utf-8') as archivo_json:\n",
    "        for linea in archivo_json:\n",
    "            try:\n",
    "                entrada = cargar_y_corregir_linea(linea)\n",
    "                user_id = entrada['user_id']\n",
    "                user_url = entrada['user_url']\n",
    "                # iteracion sobre cada items\n",
    "                for articulo in entrada['items']:\n",
    "                    writer.writerow([\n",
    "                        user_id,\n",
    "                        user_url,\n",
    "                        articulo.get('item_id', ''),\n",
    "                        articulo.get('item_name', ''),\n",
    "                        articulo.get('playtime_forever', ''),\n",
    "                        articulo.get('playtime_2weeks', ''),\n",
    "                    ])\n",
    "                    data_list.append({\n",
    "                        'user_id': user_id,\n",
    "                        'user_url': user_url,\n",
    "                        'item_id': articulo.get('item_id', ''),\n",
    "                        'item_name': articulo.get('item_name', ''),\n",
    "                        'playtime_forever': articulo.get('playtime_forever', ''),\n",
    "                        'playtime_2weeks': articulo.get('playtime_2weeks', ''),\n",
    "                    })\n",
    "            except json.JSONDecodeError as e:\n",
    "                errores_count += 1\n",
    "                print(f\"Error al procesar la línea: {e}\")\n",
    "\n",
    "    print(f\"Total de errores de JSONDecodeError detectados: {errores_count}\")\n",
    "\n",
    "# crearmos el DataFrame\n",
    "df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 'playtime_2weeks' porque no nos aporta informacion necesaria\n",
    "df.drop('playtime_2weeks', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 'user_url' porque no nos aporta informacion necesaria\n",
    "df.drop('user_url', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 'item_name' porque no nos aporta informacion necesaria\n",
    "df.drop('item_name', axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el df resultante en formato parquet \n",
    "df.to_parquet('./Datasets/user_items.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Dataset Output_Steam_games.json\n",
    "    Contiene las descripciones de los juegos de la plataforma\n",
    "    como desarrollador, año de lanzamiento y precio, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cargamos los datos desde la carpeta Datasets\n",
    "\n",
    "# Lista para almacenar los diccionarios convertidos\n",
    "data_list = []\n",
    "\n",
    "# Leer el archivo JSON línea por línea y convertir cada línea en un diccionario\n",
    "with open('./Datasets/output_steam_games.json', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # Convertir la línea en un diccionario usando json.loads\n",
    "        data_dict = json.loads(line)\n",
    "        # Añadir el diccionario a la lista\n",
    "        data_list.append(data_dict)\n",
    "\n",
    "# Convertir la lista de diccionarios en un dataframe\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Verificar el contenido de la columna 'genre'\n",
    "print(df['genres'].head())\n",
    "\n",
    "# Convertir la lista de géneros en una sola línea de texto\n",
    "df['genres'] = df['genres'].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "# Mostrar el dataframe resultante\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'id': 'item_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las columnas que no nos aportan informacion necesaria\n",
    "columnas_a_eliminar = ['title','tags', 'url', 'reviews_url', 'specs']\n",
    "\n",
    "# Eliminamos las columnas\n",
    "df = df.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para convertir los valores de 'price' a float\n",
    "def convertir_price(valor):\n",
    "    if valor is None:\n",
    "        return 0.0  # Asigna 0.0 a los valores None\n",
    "    try:\n",
    "        return float(valor)\n",
    "    except ValueError:\n",
    "        return 0.0  # Asigna 0.0 a los valores no numéricos\n",
    "\n",
    "# Aplicar la función a la columna 'price'\n",
    "df['price'] = df['price'].apply(convertir_price)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos la columna 'release_date' a datetime con manejo de errores\n",
    "df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "\n",
    "# Extraemos el año y sobrescribimos la columna 'release_date' con estos valores, y luego convertimos a int\n",
    "df['release_date'] = df['release_date'].dt.year.astype('Int64')\n",
    "\n",
    "\n",
    "# Mostrar el DataFrame para verificar la conversión\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos filas con datos faltantes\n",
    "df=df.dropna(thresh=3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el df resultante en formato parquet \n",
    "df.to_parquet('./Datasets/steam_games.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Combinaciones de Tablas para las Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a-Dataset Developer\n",
    "    Contiene nombre de los Desarrolladores, fecha de lazamiento y precio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos las columnas necesarias del df Steam_games\n",
    "developer = df[['publisher', 'release_date', 'price']]\n",
    "\n",
    "#Guardamos el df resultante en formato parquet \n",
    "developer.to_parquet('./Datasets/def_developer.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b- Dataset Userdata\n",
    "     Contiene el precio y recomendaciones de los usuarios por juego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para cumplir con los datos requeridos por la funcion necesitamos combinar \n",
    "## Steam_games con User_reviews usando item_id como conector \n",
    "\n",
    "# Cargamos los archivos Parquet\n",
    "df_steam_gamer = pd.read_parquet('./Datasets/steam_games.parquet')\n",
    "df_user_review = pd.read_parquet('./Datasets/user_reviews.parquet')\n",
    "\n",
    "# Verificamos los nombres de las columnas\n",
    "print(\"Columnas en df_steam_gamer:\")\n",
    "print(df_steam_gamer.columns)\n",
    "\n",
    "print(\"Columnas en df_user_review:\")\n",
    "print(df_user_review.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'item_id' a string en ambos DataFrames\n",
    "df_steam_gamer['item_id'] = df_steam_gamer['item_id'].astype(str)\n",
    "df_user_review['item_id'] = df_user_review['item_id'].astype(str)\n",
    "\n",
    "\n",
    "# Seleccionamos las columnas necesarias de cada DataFrame\n",
    "df_steam_gamer = df_steam_gamer[['price', 'item_id']]\n",
    "df_user_review = df_user_review[['user_id', 'item_id', 'recommend']]\n",
    "\n",
    "# Realizamos la unión usando 'item_id' como clave\n",
    "df_combined = pd.merge(df_steam_gamer, df_user_review, on='item_id', how='inner')\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_combined.info())\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame combinado en un nuevo archivo Parquet\n",
    "df_combined.to_parquet('./Datasets/def_userdata.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c- Dataset UserForGenre\n",
    "      Contiene el tiempo de juego de los usuarios por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para cumplir con los datos requeridos por la funcion necesitamos combinar \n",
    "## Steam_games con User_items usando item_id como conector \n",
    "\n",
    "# Cargamos los archivos Parquet\n",
    "df_steam_gamer = pd.read_parquet('./Datasets/steam_games.parquet')\n",
    "df_user_items = pd.read_parquet('./Datasets/user_items.parquet')\n",
    "\n",
    "# Verificamos los nombres de las columnas\n",
    "print(\"Columnas en df_steam_gamer:\")\n",
    "print(df_steam_gamer.columns)\n",
    "\n",
    "print(\"Columnas en df_user_items:\")\n",
    "print(df_user_items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'item_id' a string en ambos DataFrames\n",
    "df_steam_gamer['item_id'] = df_steam_gamer['item_id'].astype(str)\n",
    "df_user_items['item_id'] = df_user_items['item_id'].astype(str)\n",
    "\n",
    "\n",
    "# Seleccionar las columnas necesarias de df_steam_gamer\n",
    "df_steam_gamer_reduced = df_steam_gamer[['release_date', 'item_id', 'genres']]\n",
    "\n",
    "# Realizar la unión usando 'item_id' como clave\n",
    "df_combined = pd.merge(df_user_items, df_steam_gamer_reduced, on='item_id', how='inner')\n",
    "\n",
    "# Comprobar el DataFrame resultante\n",
    "print(\"Información del DataFrame combinado:\")\n",
    "print(df_combined.info())\n",
    "print(\"Primeras filas del DataFrame combinado:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame combinado en un nuevo archivo Parquet\n",
    "df_combined.to_parquet('./Datasets/def_userforgenre.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d- Dataset Best_developer_year\n",
    "      Contiene las recomendaciones de lo jugadores por items, desarroladores y año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para cumplir con los datos requeridos por la funcion necesitamos combinar \n",
    "## Steam_games con User_reviews usando item_id como conector \n",
    "\n",
    "# Cargamos los archivos Parquet\n",
    "df_steam_gamer = pd.read_parquet('./Datasets/steam_games.parquet')\n",
    "df_user_review = pd.read_parquet('./Datasets/user_reviews.parquet')\n",
    "\n",
    "# Verificamos los nombres de las columnas\n",
    "print(\"Columnas en df_steam_gamer:\")\n",
    "print(df_steam_gamer.columns)\n",
    "\n",
    "print(\"Columnas en df_user_review:\")\n",
    "print(df_user_review.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'item_id' a string en ambos DataFrames\n",
    "df_steam_gamer['item_id'] = df_steam_gamer['item_id'].astype(str)\n",
    "df_user_review['item_id'] = df_user_review['item_id'].astype(str)\n",
    "\n",
    "\n",
    "# Seleccionamos las columnas necesarias de cada DataFrame\n",
    "df_steam_gamer = df_steam_gamer[['item_id', 'publisher']]\n",
    "df_user_review = df_user_review[['item_id', 'recommend', 'review', 'posted']]\n",
    "\n",
    "# Realizamos la unión usando 'item_id' como clave\n",
    "df_combined = pd.merge(df_user_review,df_steam_gamer, on='item_id', how='inner')\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_combined.info())\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame combinado en un nuevo archivo Parquet\n",
    "df_combined.to_parquet('./Datasets/def_best_developer_year.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e- Dataset Developer_reviews_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Para cumplir con los datos requeridos por la funcion necesitamos combinar \n",
    "## Steam_games con User_reviews usando item_id como conector \n",
    "\n",
    "# Cargamos los archivos Parquet\n",
    "df_steam_gamer = pd.read_parquet('./Datasets/steam_games.parquet')\n",
    "df_user_review = pd.read_parquet('./Datasets/user_reviews.parquet')\n",
    "\n",
    "# Verificamos los nombres de las columnas\n",
    "print(\"Columnas en df_steam_gamer:\")\n",
    "print(df_steam_gamer.columns)\n",
    "\n",
    "print(\"Columnas en df_user_review:\")\n",
    "print(df_user_review.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos 'item_id' a string en ambos DataFrames\n",
    "df_steam_gamer['item_id'] = df_steam_gamer['item_id'].astype(str)\n",
    "df_user_review['item_id'] = df_user_review['item_id'].astype(str)\n",
    "\n",
    "\n",
    "# Seleccionamos las columnas necesarias de cada DataFrame\n",
    "df_steam_gamer = df_steam_gamer[['item_id', 'publisher']]\n",
    "df_user_review = df_user_review[['user_id','item_id', 'review']]\n",
    "\n",
    "# Realizamos la unión usando 'item_id' como clave\n",
    "df_combined = pd.merge(df_user_review,df_steam_gamer, on='item_id', how='inner')\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_combined.info())\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame combinado en un nuevo archivo Parquet\n",
    "df_combined.to_parquet('./Datasets/def_developer_reviews_analysis.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f- Dataset Recomendacion_usuario para el modelo de ML\n",
    "      Contiene Datos de Generos mas recomendados y jugados por los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en df_steam_gamer:\n",
      "Index(['publisher', 'genres', 'app_name', 'release_date', 'price',\n",
      "       'early_access', 'item_id', 'developer'],\n",
      "      dtype='object')\n",
      "Columnas en df_user_review:\n",
      "Index(['user_id', 'posted', 'item_id', 'recommend', 'review'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Para cumplir con los datos requeridos por la funcion necesitamos combinar \n",
    "## Steam_games con User_reviews usando item_id como conector \n",
    "\n",
    "# Cargamos los archivos Parquet\n",
    "df_steam_gamer = pd.read_parquet('./Datasets/steam_games.parquet')\n",
    "df_user_review = pd.read_parquet('./Datasets/user_reviews.parquet')\n",
    "\n",
    "# Verificamos los nombres de las columnas\n",
    "print(\"Columnas en df_steam_gamer:\")\n",
    "print(df_steam_gamer.columns)\n",
    "\n",
    "print(\"Columnas en df_user_review:\")\n",
    "print(df_user_review.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24723 entries, 0 to 24722\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   user_id   24723 non-null  object\n",
      " 1   item_id   24723 non-null  object\n",
      " 2   review    24723 non-null  int64 \n",
      " 3   app_name  24723 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 772.7+ KB\n",
      "None\n",
      "             user_id item_id  review                          app_name\n",
      "0  76561198079601835     730       1  Counter-Strike: Global Offensive\n",
      "1        MeaTCompany     730       1  Counter-Strike: Global Offensive\n",
      "2     Rainbow-Dashie     730       2  Counter-Strike: Global Offensive\n",
      "3  76561198061252210     730       2  Counter-Strike: Global Offensive\n",
      "4  76561198056741844     730       1  Counter-Strike: Global Offensive\n"
     ]
    }
   ],
   "source": [
    "# Convertimos 'item_id' a string en ambos DataFrames\n",
    "df_steam_gamer['item_id'] = df_steam_gamer['item_id'].astype(str)\n",
    "df_user_review['item_id'] = df_user_review['item_id'].astype(str)\n",
    "\n",
    "# Filtramos los datos de df_user_review donde la columna 'review' sea igual a 1 o 2\n",
    "df_user_review_filtrado = df_user_review[df_user_review['review'].isin([1, 2])]\n",
    "\n",
    "# Seleccionamos las columnas necesarias de cada DataFrame\n",
    "df_steam_gamer = df_steam_gamer[['item_id', 'app_name']]\n",
    "df_user_review_filtrado = df_user_review_filtrado[['user_id', 'item_id', 'review']]\n",
    "\n",
    "# Realizamos la unión usando 'item_id' como clave\n",
    "df_combined = pd.merge(df_user_review_filtrado, df_steam_gamer, on='item_id', how='inner')\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "print(df_combined.info())\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   user_id   10000 non-null  object\n",
      " 1   item_id   10000 non-null  object\n",
      " 2   review    10000 non-null  int64 \n",
      " 3   app_name  10000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 312.6+ KB\n",
      "None\n",
      "             user_id item_id  review                          app_name\n",
      "0  76561198079601835     730       1  Counter-Strike: Global Offensive\n",
      "1        MeaTCompany     730       1  Counter-Strike: Global Offensive\n",
      "2     Rainbow-Dashie     730       2  Counter-Strike: Global Offensive\n",
      "3  76561198061252210     730       2  Counter-Strike: Global Offensive\n",
      "4  76561198056741844     730       1  Counter-Strike: Global Offensive\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame para seleccionar solo una parte de las filas\n",
    "df_demo = df_combined.head(10000)\n",
    "\n",
    "# Mostrar información del DataFrame resultante\n",
    "print(df_demo.info())\n",
    "print(df_demo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>review</th>\n",
       "      <th>app_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76561198079601835</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MeaTCompany</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainbow-Dashie</td>\n",
       "      <td>730</td>\n",
       "      <td>2</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76561198061252210</td>\n",
       "      <td>730</td>\n",
       "      <td>2</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76561198056741844</td>\n",
       "      <td>730</td>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike: Global Offensive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Delicous_Cookies</td>\n",
       "      <td>223710</td>\n",
       "      <td>1</td>\n",
       "      <td>Cry of Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>76561198094304449</td>\n",
       "      <td>223710</td>\n",
       "      <td>1</td>\n",
       "      <td>Cry of Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>TheAussieMozzie</td>\n",
       "      <td>223710</td>\n",
       "      <td>1</td>\n",
       "      <td>Cry of Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>cbfguy</td>\n",
       "      <td>223710</td>\n",
       "      <td>1</td>\n",
       "      <td>Cry of Fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>76561198038840599</td>\n",
       "      <td>223710</td>\n",
       "      <td>1</td>\n",
       "      <td>Cry of Fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                user_id item_id  review                          app_name\n",
       "0     76561198079601835     730       1  Counter-Strike: Global Offensive\n",
       "1           MeaTCompany     730       1  Counter-Strike: Global Offensive\n",
       "2        Rainbow-Dashie     730       2  Counter-Strike: Global Offensive\n",
       "3     76561198061252210     730       2  Counter-Strike: Global Offensive\n",
       "4     76561198056741844     730       1  Counter-Strike: Global Offensive\n",
       "...                 ...     ...     ...                               ...\n",
       "9995   Delicous_Cookies  223710       1                       Cry of Fear\n",
       "9996  76561198094304449  223710       1                       Cry of Fear\n",
       "9997    TheAussieMozzie  223710       1                       Cry of Fear\n",
       "9998             cbfguy  223710       1                       Cry of Fear\n",
       "9999  76561198038840599  223710       1                       Cry of Fear\n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame combinado en un nuevo archivo Parquet\n",
    "df_demo.to_parquet('./Datasets/def_recomendacion_usuario.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
